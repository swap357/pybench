name: Benchmark-AWS

# Only allow manual triggers and restrict to specific users
on:
  workflow_dispatch:
    # Add input controls for the workflow
    inputs:
      build_from_source:
        description: 'Build Python from source'
        required: false
        default: 'true'
      iterations:
        description: 'Number of benchmark iterations'
        required: false
        default: '5'
      instance_type:
        description: 'EC2 instance type'
        required: false
        default: 'c5.2xlarge'
      cpu_pinning:
        description: 'Enable CPU pinning (yes/no)'
        required: false
        default: 'no'
      cpu_cores:
        description: 'Number of CPU cores to use (all for max)'
        required: false
        default: 'all'
      thread_limit:
        description: 'Thread limit per core (0 for unlimited)'
        required: false
        default: '1'

# Restrict permissions
permissions:
  contents: write
  pages: write
  id-token: write

jobs:
  benchmark:
    # Add user restriction
    if: github.actor == 'swap357'  # Replace with your GitHub username
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Launch EC2 instance
        id: launch-instance
        run: |
          # Debug AWS configuration
          echo "Checking AWS configuration..."
          aws sts get-caller-identity
          
          # Get default VPC ID with error checking
          echo "Getting VPC information..."
          VPC_ID=$(aws ec2 describe-vpcs \
            --filters "Name=isDefault,Values=true" \
            --query 'Vpcs[0].VpcId' \
            --output text)
          
          if [ -z "$VPC_ID" ] || [ "$VPC_ID" = "None" ]; then
            echo "Error: No default VPC found"
            exit 1
          fi
          echo "Using VPC: $VPC_ID"
          
          # Create security group
          SG_ID=$(aws ec2 create-security-group \
            --group-name benchmark-runner-sg-$(date +%s) \
            --description "Temporary SG for benchmark runner" \
            --vpc-id $VPC_ID \
            --query 'GroupId' \
            --output text)
          
          # Allow SSH access
          aws ec2 authorize-security-group-ingress \
            --group-id $SG_ID \
            --protocol tcp \
            --port 22 \
            --cidr 0.0.0.0/0
          
          # Generate key pair
          KEY_NAME="benchmark-key-$(date +%s)"
          aws ec2 create-key-pair \
            --key-name $KEY_NAME \
            --query 'KeyMaterial' \
            --output text > benchmark_key.pem
          chmod 600 benchmark_key.pem
          
          # Get all available subnets in the VPC
          SUBNET_IDS=$(aws ec2 describe-subnets \
            --filters "Name=vpc-id,Values=$VPC_ID" "Name=default-for-az,Values=true" \
            --query 'Subnets[*].SubnetId' \
            --output text)
          
          # Try launching in each subnet until successful
          INSTANCE_ID=""
          for SUBNET_ID in $SUBNET_IDS; do
            echo "Attempting to launch in subnet $SUBNET_ID"
            if INSTANCE_ID=$(aws ec2 run-instances \
              --image-id ${{ secrets.AWS_AMI_ID }} \
              --instance-type ${{ inputs.instance_type }} \
              --key-name $KEY_NAME \
              --subnet-id $SUBNET_ID \
              --security-group-ids $SG_ID \
              --associate-public-ip-address \
              --tag-specifications 'ResourceType=instance,Tags=[{Key=Name,Value=benchmark-runner}]' \
              --query 'Instances[0].InstanceId' \
              --output text 2>/dev/null); then
              echo "Successfully launched instance in subnet $SUBNET_ID"
              break
            else
              echo "Failed to launch in subnet $SUBNET_ID, trying next subnet..."
            fi
          done
          
          if [ -z "$INSTANCE_ID" ]; then
            echo "Failed to launch instance in any subnet"
            exit 1
          fi
          
          # Save outputs
          {
            echo "instance_id=$INSTANCE_ID"
            echo "sg_id=$SG_ID"
            echo "key_name=$KEY_NAME"
          } >> "$GITHUB_OUTPUT"
          
          # Wait for instance to be running
          aws ec2 wait instance-running --instance-ids $INSTANCE_ID
          
          # Get instance public IP
          PUBLIC_IP=$(aws ec2 describe-instances \
            --instance-ids $INSTANCE_ID \
            --query 'Reservations[0].Instances[0].PublicIpAddress' \
            --output text)
          
          echo "public_ip=$PUBLIC_IP" >> "$GITHUB_OUTPUT"

      - name: Wait for instance boot
        run: sleep 30

      - name: Run benchmarks
        run: |
          # Configure SSH for better stability
          mkdir -p ~/.ssh
          cat >> ~/.ssh/config << 'EOF'
          Host *
            ServerAliveInterval 60
            ServerAliveCountMax 10
            TCPKeepAlive yes
          EOF
          
          # Wait for SSH to be available
          for i in {1..5}; do
            if ssh -o StrictHostKeyChecking=no -i benchmark_key.pem ubuntu@${{ steps.launch-instance.outputs.public_ip }} echo "SSH connection successful"; then
              break
            fi
            echo "Waiting for SSH to be available (attempt $i)..."
            sleep 30
          done
          
          # Create remote directory structure
          ssh -o StrictHostKeyChecking=no -i benchmark_key.pem ubuntu@${{ steps.launch-instance.outputs.public_ip }} "mkdir -p ~/pybench"
          
          # Copy entire repository to remote instance
          scp -o StrictHostKeyChecking=no -i benchmark_key.pem \
            -r ./* \
            ubuntu@${{ steps.launch-instance.outputs.public_ip }}:~/pybench/
          
          # Install package in development mode using existing pyenv setup
          ssh -o StrictHostKeyChecking=no -i benchmark_key.pem ubuntu@${{ steps.launch-instance.outputs.public_ip }} "
            export PYENV_ROOT=\"\$HOME/.pyenv\" && \
            export PATH=\"\$PYENV_ROOT/bin:\$PATH\" && \
            eval \"\$(pyenv init -)\" && \
            cd ~/pybench && \
            # Ensure pip is installed and updated
            curl -sS https://bootstrap.pypa.io/get-pip.py | python3 && \
            python3 -m pip install --upgrade pip && \
            pip install -e .
          "

          # Create benchmark script
          cat << 'EOF' > run_benchmark.sh
          #!/bin/bash
          set -e
          
          # Load pyenv
          export PYENV_ROOT="$HOME/.pyenv"
          export PATH="$PYENV_ROOT/bin:$PATH"
          eval "$(pyenv init -)"
          
          # Get CPU info
          TOTAL_CORES=$(nproc)
          
          # Set CPU cores
          if [ "$1" = "all" ]; then
            CORES_TO_USE=$TOTAL_CORES
          else
            CORES_TO_USE=$1
            [ $CORES_TO_USE -gt $TOTAL_CORES ] && CORES_TO_USE=$TOTAL_CORES
          fi
          
          # Set thread limits
          if [ "$2" != "0" ]; then
            THREAD_COUNT=$(( CORES_TO_USE * $2 ))
            export OMP_NUM_THREADS=$THREAD_COUNT
            export MKL_NUM_THREADS=$THREAD_COUNT
            export OPENBLAS_NUM_THREADS=$THREAD_COUNT
            export VECLIB_MAXIMUM_THREADS=$THREAD_COUNT
            export NUMEXPR_NUM_THREADS=$THREAD_COUNT
          fi
          
          cd ~/pybench
          
          # Run benchmark
          if [ "$3" = "yes" ]; then
            echo "Running with CPU pinning on cores 0-$((CORES_TO_USE - 1))"
            taskset -c 0-$((CORES_TO_USE - 1)) python benchmark_runner.py \
              --report both \
              --iterations "$5"
          else
            echo "Running without CPU pinning, using $CORES_TO_USE cores"
            python benchmark_runner.py \
              --report both \
              --iterations "$5"
          fi
          EOF
          
          chmod +x run_benchmark.sh
          
          # Copy run script
          scp -o StrictHostKeyChecking=no -i benchmark_key.pem \
            run_benchmark.sh \
            ubuntu@${{ steps.launch-instance.outputs.public_ip }}:~/
          
          # Execute benchmark
          ssh -o StrictHostKeyChecking=no -i benchmark_key.pem ubuntu@${{ steps.launch-instance.outputs.public_ip }} \
            "./run_benchmark.sh '${{ inputs.cpu_cores }}' '${{ inputs.thread_limit }}' '${{ inputs.cpu_pinning }}' '${{ inputs.profile_level }}' '${{ inputs.iterations }}'"
          
          # Copy results back
          scp -o StrictHostKeyChecking=no -i benchmark_key.pem \
            ubuntu@${{ steps.launch-instance.outputs.public_ip }}:~/pybench/benchmark_results.json .

      - name: Install script dependencies
        run: |
          python -m pip install plotly kaleido beautifulsoup4

      - name: Process results
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # Clean up files that might interfere with git checkout
          rm -f benchmark_key.pem run_benchmark.sh
          
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          
          TIMESTAMP=$(date +%Y%m%d_%H%M%S)
          
          mkdir -p /tmp/benchmark_results/runs/${TIMESTAMP}
          cp -r scripts /tmp/benchmark_results/
          cp benchmark_results.json "/tmp/benchmark_results/runs/${TIMESTAMP}/results.json"
          
          python /tmp/benchmark_results/scripts/json_to_html.py \
            --input-file benchmark_results.json \
            --output-dir "/tmp/benchmark_results/runs/${TIMESTAMP}" \
            --run-id "${TIMESTAMP}"
          
          # Clean working directory before git operations
          git clean -fd
          git fetch origin gh-pages
          
          if git ls-remote --heads origin gh-pages | grep gh-pages > /dev/null; then
            git checkout gh-pages
            git pull origin gh-pages
          else
            git checkout --orphan gh-pages
            git rm -rf .
            mkdir -p runs
            cp /tmp/benchmark_results/scripts/index_template.html index.html
          fi
          
          mkdir -p "runs/${TIMESTAMP}"
          cp -r "/tmp/benchmark_results/runs/${TIMESTAMP}"/* "runs/${TIMESTAMP}/"
          
          python /tmp/benchmark_results/scripts/update_index.py \
            --input-file "runs/${TIMESTAMP}/results.json" \
            --index-file index.html \
            --run-id "${TIMESTAMP}"
          
          rm -rf __pycache__ *.pyc python_benchmark_suite.egg-info benchmark_results.json
          
          git add -A
          
          if git status --porcelain | grep .; then
            git commit -m "Add AWS benchmark results for run ${TIMESTAMP}"
            git push origin gh-pages
          fi

      - name: Cleanup resources
        if: always()
        run: |
          # Terminate instance
          if [ -n "${{ steps.launch-instance.outputs.instance_id }}" ]; then
            echo "Terminating instance..."
            aws ec2 terminate-instances --instance-ids ${{ steps.launch-instance.outputs.instance_id }}
            aws ec2 wait instance-terminated --instance-ids ${{ steps.launch-instance.outputs.instance_id }}
          fi
          
          # Delete security group
          if [ -n "${{ steps.launch-instance.outputs.sg_id }}" ]; then
            echo "Deleting security group..."
            sleep 10  # Wait for instance termination to propagate
            aws ec2 delete-security-group --group-id ${{ steps.launch-instance.outputs.sg_id }} || true
          fi
          
          # Delete key pair
          if [ -n "${{ steps.launch-instance.outputs.key_name }}" ]; then
            echo "Deleting key pair..."
            aws ec2 delete-key-pair --key-name ${{ steps.launch-instance.outputs.key_name }}
          fi
